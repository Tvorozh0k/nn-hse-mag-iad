# Lab 2

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tvorozh0k/nn-hse-mag-iad/blob/main/Data-Mining-Tools/lab2/Data_Mining_Tools_Lab_2.ipynb)

## Tasks

Решить задачу классификации рукописных цифр на датасете MNIST https://www.kaggle.com/datasets/hojjatk/mnist-dataset. Правила следующие:

* Нужно представить решение в виде нейронной сети, написанной на `numpy`, и обученной с помощью алгоритма градиентного спуска;

* Нейронная сеть должна состоять из двух линейных слоев, активаций `relu` и `softmax`, и `mse` лосса - каждый оформлен в виде класса с методами `forward` и `backward`;

* Нельзя пользоваться автоградиентом (`pytorch`, `numpy`), за исключением тестов. Градиенты должны считаться вручную по алгоритму обратного распространения ошибки, использующему аналитические формулы производных;

* Для каждого слоя должны быть реализованы тесты методов `forward` и `backward`. Нужно убедиться, что аутпуты этих методов совпадают с результатами в `pytorch`;

* В качестве лосса хотим использовать `MSELoss`

**Критерии оценивания:**

* Базовая 6 баллов;

* Правильные линейный `forward` + `backward` с тестами: +1 балл;

* Правильные классы активации `softmax` и `relu` с тестами: +1 балл;

* Правильный класс `MSELoss` с тестами: +1 балл;

* Плохое оформление кода - нет классов и разделений на функции: -1 балл;

* Слишком медленный код: -1 балл. (если код можно ускорить в 10 раз);

* `CrossEntropy` вместо `MSELoss`: -2 балла;
    
* Математические ошибки: -2 балла (даже если результат сошелся!)